<div align="center">

# ğŸ›¡ï¸ AI Security Labs Handbook

**Production-Grade AI Security Patterns for LLM Applications**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688.svg?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com)
[![OPA](https://img.shields.io/badge/OPA-Policy-7B68EE.svg)](https://www.openpolicyagent.org/)

**[ğŸ§ª Labs](#-laboratory-series) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“š Learn](#-what-youll-learn) â€¢ [ğŸ¤ Contributing](#-contributing)**

---

### ğŸ¯ **Hands-on laboratories demonstrating AI security across different architectures**

**Simple LLMs â€¢ RAG Systems â€¢ Agentic AI**

</div>

---

## ğŸ“– Overview

This handbook provides **practical, runnable examples** of AI security implementations that work across different deployment models - whether you're using **local open-source models** (Ollama), **cloud APIs** (OpenAI, Anthropic), or **proprietary in-house models**.

### Why This Handbook?

- âœ… **Learn by doing** - Real, working code you can run locally
- âœ… **Provider-agnostic** - Security patterns work with any LLM
- âœ… **Enterprise-ready** - Patterns used in production systems
- âœ… **Comprehensive** - Covers LLMs, RAG, and Agentic AI
- âœ… **Open source** - MIT licensed, free to use and modify

---

## ğŸ”‘ Core Concept: Provider-Agnostic Security

Security layers operate **independently of your LLM provider**, making your security investment portable and future-proof.

### Architecture Overview

<table>
<tr>
<td colspan="2" align="center"><strong>ğŸ¯ Your Application Layer</strong></td>
</tr>
<tr>
<td colspan="2" align="center">â¬‡ï¸</td>
</tr>
<tr>
<td colspan="2" align="center" bgcolor="#fff4e6"><strong>ğŸ›¡ï¸ Security Gateway (Provider-Agnostic)</strong></td>
</tr>
<tr>
<td width="50%" valign="top">
<strong>ğŸ“¥ Pre-Processing</strong>
<ul>
<li>âœ“ PII Detection & Masking</li>
<li>âœ“ Prompt Injection Detection</li>
<li>âœ“ Policy Enforcement (OPA)</li>
<li>âœ“ Input Validation</li>
</ul>
</td>
<td width="50%" valign="top">
<strong>ğŸ“¤ Post-Processing</strong>
<ul>
<li>âœ“ Output Sanitization</li>
<li>âœ“ Response DLP</li>
<li>âœ“ Provenance Tracking</li>
</ul>
</td>
</tr>
<tr>
<td colspan="2" align="center">â¬‡ï¸</td>
</tr>
<tr>
<td colspan="2" align="center" bgcolor="#e8f5e9">
<strong>ğŸ”Œ LLM Provider (Interchangeable)</strong><br/>
Ollama (Local) â€¢ OpenAI/Anthropic (Cloud) â€¢ Azure OpenAI (Enterprise) â€¢ Custom In-House
</td>
</tr>
</table>

> **ğŸ’¡ Key Insight**: Security processors work with data structures, not API calls. Write security logic once, use everywhere.

### Multi-Provider Support

| Deployment Model | Example | Code Change Required | Security Processors |
|-----------------|---------|---------------------|-------------------|
| **ğŸ  Local/On-Prem** | Ollama, vLLM, TGI | Update `providers.py` (30 lines) | âœ… No change |
| **â˜ï¸ Cloud API** | OpenAI, Anthropic, Cohere | Update `providers.py` (30 lines) | âœ… No change |
| **ğŸ¢ Enterprise** | Azure OpenAI, AWS Bedrock | Update `providers.py` (30 lines) | âœ… No change |
| **ğŸ”§ In-House** | Custom fine-tuned models | Update `providers.py` (30 lines) | âœ… No change |

ğŸ“– **[Read Provider Integration Guide â†’](docs/PROVIDERS.md)**

---

## ğŸ§ª Laboratory Series

<table>
<tr>
<td width="33%" align="center">

### ğŸ” Lab 01
**PII-Safe Summarizer**

âœ… **COMPLETE**

Foundation security patterns for LLM applications

**Features:**
- PII Detection & Masking
- Prompt Injection Guards
- ABAC Policies
- Performance Monitoring

[**ğŸ“– Enter Lab 01 â†’**](labs/01-pii-safe-summarizer/)

**Time:** 2-3 hours  
**Difficulty:** ğŸŸ¢ Beginner

</td>
<td width="33%" align="center">

### ğŸ” Lab 02
**Secure RAG Copilot**

ğŸš§ **COMING SOON**

RAG-specific security patterns

**Features:**
- Context Injection Prevention
- Retrieval Authorization
- Citation Verification
- Embedding Security

[**ğŸ”® Preview Lab 02 â†’**](labs/02-secure-rag-copilot/)

**Time:** 3-4 hours  
**Difficulty:** ğŸŸ¡ Intermediate

</td>
<td width="33%" align="center">

### ğŸ¤– Lab 03
**Governed AI Agents**

ğŸš§ **COMING SOON**

Autonomous system governance

**Features:**
- Tool Authorization
- Action Approval Workflows
- Sandboxing & Limits
- Decision Audit Trails

[**ğŸ”® Preview Lab 03 â†’**](labs/03-governed-ai-agent/)

**Time:** 4-5 hours  
**Difficulty:** ğŸ”´ Advanced

</td>
</tr>
</table>

### ğŸ—ºï¸ Learning Path
