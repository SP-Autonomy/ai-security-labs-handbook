<div align="center">

# ğŸ›¡ï¸ AI Security Labs Handbook

**Production-Grade Security Patterns for Modern AI Systems**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688.svg?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com)
[![OPA](https://img.shields.io/badge/OPA-Policy-7B68EE.svg)](https://www.openpolicyagent.org/)
[![Labs](https://img.shields.io/badge/labs-3%2F3%20complete-success.svg)](.)

**[ğŸ§ª Labs](#-laboratory-series) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“š Security Frameworks](#-security-frameworks) â€¢ [ğŸ“ Learn](#-what-youll-learn)**

---

### ğŸ¯ **Hands-on security laboratories covering the full AI application spectrum**

**Simple LLMs â†’ RAG Systems â†’ Multi-Agent AI**

**100% Complete** â€¢ **Provider-Agnostic** â€¢ **Production-Ready**

</div>

---

## ğŸ“– Overview

A comprehensive, **hands-on security handbook** with 3 progressive laboratories demonstrating AI security implementations that work across **any LLM provider** - from local Ollama to OpenAI, Anthropic, Azure OpenAI, or custom in-house models.

### Why This Handbook?

<table>
<tr>
<td width="50%">

**ğŸ¯ Practical Learning**
- âœ… Real, working code you can run locally
- âœ… Complete test suites with expected results
- âœ… Evidence-based validation
- âœ… Step-by-step documentation

</td>
<td width="50%">

**ğŸ¢ Enterprise-Ready**
- âœ… Patterns from production systems
- âœ… Defense-in-depth architectures
- âœ… Comprehensive audit trails
- âœ… Policy-driven governance

</td>
</tr>
<tr>
<td width="50%">

**ğŸ”§ Provider-Agnostic**
- âœ… Works with any LLM (local or cloud)
- âœ… Portable security investment
- âœ… Future-proof implementations
- âœ… No vendor lock-in

</td>
<td width="50%">

**ğŸ“š Progressive Curriculum**
- âœ… Beginner to advanced difficulty
- âœ… Builds on previous concepts
- âœ… Covers all AI architectures
- âœ… Industry-standard frameworks

</td>
</tr>
</table>

---

## ğŸ“ What You'll Learn

### Security Skills Across All Labs

| Skill Area | Lab 01 | Lab 02 | Lab 03 |
|------------|--------|--------|--------|
| **Input Validation** | âœ… Prompt injection detection | âœ… Context injection detection | âœ… Tool parameter validation |
| **Output Sanitization** | âœ… PII masking | âœ… Citation tracking | âœ… Exfiltration detection |
| **Access Control** | âœ… RBAC/ABAC policies | âœ… Document-level filtering | âœ… Per-agent tool allowlists |
| **Audit & Compliance** | âœ… Provenance metadata | âœ… Source attribution | âœ… Immutable evidence logs |
| **Defense-in-Depth** | âœ… 5-layer chain | âœ… 9-layer chain | âœ… Context-aware risk scoring |
| **Threat Detection** | âœ… Pattern matching | âœ… Content validation | âœ… Behavioral anomalies |

### By the End of This Handbook

You'll be able to:

âœ… **Secure traditional LLM applications** with PII protection, injection detection, and policy enforcement  
âœ… **Defend RAG systems** against indirect injection, content poisoning, and information leakage  
âœ… **Govern autonomous agents** with tool authorization, sandboxing, and comprehensive monitoring  
âœ… **Implement defense-in-depth** security architectures for any AI system  
âœ… **Build provider-agnostic** security that works across all LLM platforms  
âœ… **Create audit trails** that meet enterprise compliance requirements

---

## ğŸ”‘ Core Concept: Provider-Agnostic Security

Security layers operate **independently of your LLM provider**, making your security investment **portable** and **future-proof**.

### Architecture Pattern
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Your Application                       â”‚
â”‚          (Summarizer / RAG / Agentic AI )               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ğŸ›¡ï¸ Security Gateway (Provider-Agnostic)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Pre-Processing              Post-Processing            â”‚
â”‚  â”œâ”€ DLP (PII Detection)      â”œâ”€ Output Sanitization     â”‚
â”‚  â”œâ”€ Injection Detection      â”œâ”€ Response DLP            â”‚
â”‚  â”œâ”€ Policy Enforcement       â”œâ”€ Provenance Tracking     â”‚
â”‚  â”œâ”€ Context Validation       â””â”€ Citation Verification   â”‚
â”‚  â””â”€ Tool Authorization                                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸ”Œ LLM Provider Interface (30-line adapter)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚            â”‚
        â†“            â†“            â†“            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Ollama â”‚  â”‚ OpenAI â”‚  â”‚ Azure  â”‚  â”‚ Custom â”‚
    â”‚ (Local)â”‚  â”‚ (Cloud)â”‚  â”‚  OpenAIâ”‚  â”‚In-Houseâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **ğŸ’¡ Key Insight**: Security operates on **data structures**, not API calls. Write security logic **once**, use **everywhere**.

### Switching Providers

All security remains **unchanged** when switching LLM providers:
```python
# Only this file changes (30 lines):
# shared/gateway/providers.py

def call_llm(prompt: str) -> str:
    if PROVIDER == "ollama":
        return ollama.generate(...)      # Local
    elif PROVIDER == "openai":
        return openai.chat.completions.create(...)  # Cloud
    elif PROVIDER == "azure":
        return azure_openai.chat.completions.create(...)  # Enterprise
    elif PROVIDER == "custom":
        return your_model.predict(...)   # In-house
```

**Security processors (`dlp.py`, `injection.py`, `policy_opa.py`, etc.):** âœ… **No changes required**

---

## ğŸ§ª Laboratory Series

<table>
<thead>
<tr>
<th width="33%">Lab 01: Foundation</th>
<th width="33%">Lab 02: RAG Security</th>
<th width="33%">Lab 03: Agentic AI</th>
</tr>
</thead>
<tbody>
<tr>
<td valign="top">

### ğŸ” PII-Safe Summarizer

**âœ… COMPLETE**

Foundational security patterns for LLM applications

**Security Controls:**
- âœ… PII Detection & Masking
- âœ… Prompt Injection Guards
- âœ… RBAC/ABAC Policies (OPA)
- âœ… Provenance Tracking
- âœ… Performance Monitoring

**Threat Coverage:**
- OWASP LLM01 (Injection)
- OWASP LLM06 (Sensitive Info)
- OWASP LLM08 (Excessive Agency)

**What You'll Build:**  
Secure summarization service with 5-layer defense-in-depth

[**ğŸ“– Start Lab 01 â†’**](labs/pii-safe-summarizer/)

â±ï¸ **2-3 hours**  
ğŸ¯ **Beginner**

</td>
<td valign="top">

### ğŸ” Secure RAG Copilot

**âœ… COMPLETE**

RAG-specific security patterns and retrieval safety

**Security Controls:**
- âœ… Indirect Injection Defense
- âœ… Content Validation (Pre-Ingestion)
- âœ… Context Sanitization
- âœ… Source Attribution
- âœ… Vector Search Security

**Threat Coverage:**
- OWASP LLM01 (Indirect Injection)
- OWASP LLM03 (Corpus Poisoning)
- OWASP LLM06 (Info Disclosure)

**What You'll Build:**  
RAG copilot with 9-layer security chain and test/prod separation

[**ğŸ“– Start Lab 02 â†’**](labs/rag_copilot/)

â±ï¸ **2-3 hours**  
ğŸ¯ **Intermediate**

</td>
<td valign="top">

### ğŸ¤– Governed Agentic AI

**âœ… COMPLETE**

Multi-agent governance with MCP-style tool control

**Security Controls:**
- âœ… OPA Tool Authorization
- âœ… Context-Aware Risk Scoring
- âœ… Budget Enforcement
- âœ… Sandbox Path Protection
- âœ… Evidence-Based Auditing

**Threat Coverage:**
- MAESTRO (11/12 categories)
- OWASP LLM01, 06, 08, 10
- Tool misuse, exfiltration, goal misalignment

**What You'll Build:**  
3-agent orchestration system with comprehensive governance

[**ğŸ“– Start Lab 03 â†’**](labs/governed_agentic_ai/)

â±ï¸ **3-4 hours**  
ğŸ¯ **Advanced**

</td>
</tr>
</tbody>
</table>

### ğŸ—ºï¸ Recommended Learning Path
```
Start Here
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lab 01: PII-Safe Summarizer (2-3 hours)  â”‚  â† Foundation
â”‚  â€¢ Input validation                        â”‚
â”‚  â€¢ Output sanitization                     â”‚
â”‚  â€¢ Policy enforcement                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lab 02: Secure RAG Copilot (2-3 hours)   â”‚  â† RAG-Specific
â”‚  â€¢ Retrieval security                      â”‚
â”‚  â€¢ Indirect injection defense              â”‚
â”‚  â€¢ Content validation                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lab 03: Governed Agentic AI (3-4 hours)  â”‚  â† Autonomous Systems
â”‚  â€¢ Tool authorization                      â”‚
â”‚  â€¢ Behavioral monitoring                   â”‚
â”‚  â€¢ Context-aware risk scoring              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
         Production Ready! ğŸ‰
```

**Total Time:** ~8-10 hours for complete mastery

---

## ğŸ“Š Security Frameworks

This handbook maps to industry-standard security frameworks:

### OWASP LLM Top 10 Coverage

| Threat | Lab 01 | Lab 02 | Lab 03 | Mitigation |
|--------|--------|--------|--------|------------|
| **LLM01: Prompt Injection** | âœ… | âœ… | âœ… | Pattern detection + context analysis |
| **LLM03: Training/Corpus Poisoning** | - | âœ… | - | Pre-ingestion validation |
| **LLM06: Sensitive Info Disclosure** | âœ… | âœ… | âœ… | DLP + PII masking |
| **LLM08: Excessive Agency** | âœ… | - | âœ… | Policy gates + tool allowlists |
| **LLM10: Model DoS** | âœ… | - | âœ… | Budget enforcement + rate limits |

### MAESTRO Framework (Agentic AI)

Lab 03 provides comprehensive coverage of the **MAESTRO** threat ontology:

| Category | Coverage | Controls |
|----------|----------|----------|
| Tool Misuse | 100% | OPA allowlists + budget enforcement |
| Information Leakage | 100% | Pattern detection + evidence logging |
| Goal Misalignment | 100% | Context-aware risk scoring |
| Environmental Manipulation | 100% | Sandbox + path validation |
| A2A Trust | 100% | Per-agent identity + authorization |
| Schema Violations | 100% | JSON Schema validation |

**Total:** 11/12 MAESTRO categories addressed âœ…

---

## ğŸš€ Quick Start

### Prerequisites

<table>
<tr>
<td width="50%">

**Required:**
- âœ… Python 3.11+
- âœ… Git
- âœ… 8GB RAM minimum

</td>
<td width="50%">

**Choose One LLM Provider:**
- ğŸ¦™ [Ollama](https://ollama.com/download) (Recommended - free, local)
- ğŸ¤– OpenAI API key
- âš¡ Anthropic API key
- ğŸ¢ Azure OpenAI credentials

</td>
</tr>
<tr>
<td colspan="2">

**Additional Tools:**
- âœ… [OPA](https://www.openpolicyagent.org/docs/latest/#running-opa) - Open Policy Agent (for policy enforcement)
- âœ… curl or httpie (for testing)
- âœ… jq (optional - for JSON parsing)

</td>
</tr>
</table>

### Installation (5 Minutes)
```bash
# 1. Clone repository
git clone https://github.com/SP-authonomy/ai-security-labs-handbook.git
cd ai-security-labs-handbook

# 2. Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set up Ollama (if using local models)
ollama pull llama3.2:1b           # For Labs 1, 2, 3
ollama pull nomic-embed-text      # For Lab 2, 3 (embeddings)

# 5. Configure environment
cp .env.example .env
# Edit .env with your settings (or keep defaults for Ollama)

# 6. Start OPA (separate terminal)
opa run --server --log-level error
```

### Quick Test (Verify Setup)
```bash
# Start OPA policies (terminal 1)
make run-opa

# Test Lab 01 (terminal 2)
make run-api
# In terminal 3:
make test-benign-employee
# Expected: âœ… SUCCESS

# You're ready! ğŸ‰
```

---

## ğŸ“š Documentation Structure

Each lab includes comprehensive documentation:
```
labs/
â”œâ”€â”€ pii-safe-summarizer/
â”‚   â”œâ”€â”€ README.md              # Setup, architecture, tests
â”‚   â”œâ”€â”€ RESULTS.md             # Empirical test results
â”‚   â”œâ”€â”€ app/                   # FastAPI application
â”‚   â”œâ”€â”€ policies/              # OPA policies
â”‚   â””â”€â”€ redteam/               # Attack simulations
â”‚
â”œâ”€â”€ rag_copilot/
â”‚   â”œâ”€â”€ README.md              # RAG-specific security
â”‚   â”œâ”€â”€ RESULTS.md             # Validation results
â”‚   â”œâ”€â”€ app/                   # RAG application
â”‚   â”œâ”€â”€ data/corpus/           # Trusted documents
â”‚   â”œâ”€â”€ redteam/ipi_pages/     # Malicious docs for testing
â”‚   â””â”€â”€ policies/              # Content validation
â”‚
â””â”€â”€ governed_agentic_ai/
    â”œâ”€â”€ README.md              # Multi-agent governance
    â”œâ”€â”€ RESULTS.md             # MAESTRO validation
    â”œâ”€â”€ app/                   # Agent orchestrator
    â”œâ”€â”€ agent/                 # Agent implementations
    â”œâ”€â”€ tools/                 # Tool registry
    â”œâ”€â”€ policies/              # OPA tool policies
    â””â”€â”€ security/              # Context analyzer
```

---

## ğŸ› ï¸ Technology Stack

<table>
<tr>
<td width="50%">

**Core Framework**
- Python 3.11+
- FastAPI (async web framework)
- Pydantic (data validation)
- asyncio (concurrent processing)

**Security**
- OPA (policy enforcement)
- JSON Schema (validation)
- Regex (pattern matching)
- Custom security processors

</td>
<td width="50%">

**LLM Integration**
- Ollama (local models)
- OpenAI SDK (cloud)
- Anthropic SDK (cloud)
- ChromaDB (vector storage - Lab 02)

**Testing & Monitoring**
- pytest (unit tests)
- curl (integration tests)
- Evidence logging (JSONL)
- Performance metrics

</td>
</tr>
</table>

---

## ğŸ¯ Use Cases

This handbook is for:

| Role | Use Case |
|------|----------|
| **ğŸ”’ Security Engineers** | Learn AI-specific security patterns and threat models |
| **ğŸ‘¨â€ğŸ’» AI/ML Engineers** | Add production-grade security to AI applications |
| **ğŸ¢ Enterprise Architects** | Design secure, compliant AI systems |
| **ğŸ“ Students & Researchers** | Study practical AI security implementations |
| **ğŸš€ Startup Founders** | Build secure AI products from day one |
| **ğŸ“Š Compliance Teams** | Understand AI audit and governance requirements |

### Real-World Applications

- âœ… **Customer Support Bots** with PII protection (Lab 01)
- âœ… **Enterprise Knowledge Bases** with RAG security (Lab 02)
- âœ… **AI Research Assistants** with tool governance (Lab 03)
- âœ… **Document Processing Pipelines** with content validation
- âœ… **Automated Workflow Systems** with decision auditing

---

## ğŸ“ˆ Performance Benchmarks

Security overhead across all labs:

| Lab | Security Layers | Overhead | Impact |
|-----|----------------|----------|--------|
| **Lab 01** | 5 layers | <15ms (<1%) | âœ… Minimal |
| **Lab 02** | 9 layers | <100ms (<1%) | âœ… Minimal |
| **Lab 03** | Context-aware | <4ms (<0.02%) | âœ… Negligible |

**Key Finding:** Security adds **<1% latency** in all scenarios. LLM call time (10-30s) dominates.

---


## ğŸ“„ License

MIT License - Free to use, modify, and distribute.

See [LICENSE](LICENSE) for full details.

---

## ğŸ™ Acknowledgments

Built with insights from:

- **OWASP LLM Top 10** - AI security threat taxonomy
- **MAESTRO Framework** - Multi-agent security research
- **Anthropic's Research** - Constitutional AI and safety
- **OpenAI's Best Practices** - Prompt engineering and safety
- **Production systems** - Real-world security patterns

---


<div align="center">

## ğŸ“ Ready to Master AI Security?

**Start with Lab 01 and build production-ready security in less than 10 hours**

**[ğŸš€ Begin Lab 01: PII-Safe Summarizer â†’](labs/pii-safe-summarizer/)**

---

*Last Updated: October 2025*

</div>