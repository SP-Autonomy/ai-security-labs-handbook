<div align="center">

# ğŸ›¡ï¸ AI Security Labs Handbook

**Production-Grade AI Security Patterns for LLM Applications**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688.svg?style=flat&logo=FastAPI&logoColor=white)](https://fastapi.tiangolo.com)
[![OPA](https://img.shields.io/badge/OPA-Policy-7B68EE.svg)](https://www.openpolicyagent.org/)

**[ğŸ§ª Labs](#-laboratory-series) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“š Learn](#-learning-path)**

---

### ğŸ¯ **Hands-on laboratories demonstrating AI security across different architectures**

**Simple LLMs â€¢ RAG Systems â€¢ Agentic AI**

</div>

---

## ğŸ“– Overview

This handbook provides **practical, runnable examples** of AI security implementations that work across different deployment models - whether you're using **local open-source models** (Ollama), **cloud APIs** (OpenAI, Anthropic), or **proprietary in-house models**.

### Why This Handbook?

- âœ… **Learn by doing** - Real, working code you can run locally
- âœ… **Provider-agnostic** - Security patterns work with any LLM
- âœ… **Enterprise-ready** - Patterns used in production systems
- âœ… **Comprehensive** - Covers LLMs, RAG, and Agentic AI
- âœ… **Open source** - MIT licensed, free to use and modify

---

## ğŸ”‘ Core Concept: Provider-Agnostic Security

Security layers operate **independently of your LLM provider**, making your security investment portable and future-proof.

### Architecture Overview

<table>
<tr>
<td colspan="2" align="center"><strong>ğŸ¯ Your Application Layer</strong></td>
</tr>
<tr>
<td colspan="2" align="center">â¬‡ï¸</td>
</tr>
<tr>
<td colspan="2" align="center" bgcolor="#fff4e6"><strong>ğŸ›¡ï¸ Security Gateway (Provider-Agnostic)</strong></td>
</tr>
<tr>
<td width="50%" valign="top">
<strong>ğŸ“¥ Pre-Processing</strong>
<ul>
<li>âœ“ PII Detection & Masking</li>
<li>âœ“ Prompt Injection Detection</li>
<li>âœ“ Policy Enforcement (OPA)</li>
<li>âœ“ Input Validation</li>
</ul>
</td>
<td width="50%" valign="top">
<strong>ğŸ“¤ Post-Processing</strong>
<ul>
<li>âœ“ Output Sanitization</li>
<li>âœ“ Response DLP</li>
<li>âœ“ Provenance Tracking</li>
</ul>
</td>
</tr>
<tr>
<td colspan="2" align="center">â¬‡ï¸</td>
</tr>
<tr>
<td colspan="2" align="center" bgcolor="#e8f5e9">
<strong>ğŸ”Œ LLM Provider (Interchangeable)</strong><br/>
Ollama (Local) â€¢ OpenAI/Anthropic (Cloud) â€¢ Azure OpenAI (Enterprise) â€¢ Custom In-House
</td>
</tr>
</table>

> **ğŸ’¡ Key Insight**: Security processors work with data structures, not API calls. Write security logic once, use everywhere.

### Multi-Provider Support

| Deployment Model | Example | Code Change Required | Security Processors |
|-----------------|---------|---------------------|-------------------|
| **ğŸ  Local/On-Prem** | Ollama, vLLM, TGI | Update `providers.py` (30 lines) | âœ… No change |
| **â˜ï¸ Cloud API** | OpenAI, Anthropic, Cohere | Update `providers.py` (30 lines) | âœ… No change |
| **ğŸ¢ Enterprise** | Azure OpenAI, AWS Bedrock | Update `providers.py` (30 lines) | âœ… No change |
| **ğŸ”§ In-House** | Custom fine-tuned models | Update `providers.py` (30 lines) | âœ… No change |

---

## ğŸ§ª Laboratory Series

<table>
<tr>
<td width="33%" align="center">

### ğŸ” Lab 01
**PII-Safe Summarizer**

âœ… **COMPLETE**

Foundation security patterns for LLM applications

**Features:**
- PII Detection & Masking
- Prompt Injection Guards
- RBAC/ABAC Policies
- Performance Monitoring

[**ğŸ“– Enter Lab 01 â†’**](labs/pii-safe-summarizer/)

**Time:** 2-3 hours  
**Difficulty:** ğŸŸ¢ Beginner

</td>
<td width="33%" align="center">

### ğŸ” Lab 02
**Secure RAG Copilot**

âœ… **COMPLETE**

RAG-specific security patterns

**Features:**
- Indirect Prompt Injection Defense
- Content Validation (Pre-Ingestion) and Sanitization
- Embedding Security
- DLP + Policy Gate + Provenance

[**ğŸ”® Preview Lab 02 â†’**](labs/rag_copilot/)

**Time:** 3-4 hours  
**Difficulty:** ğŸŸ¡ Intermediate

</td>
<td width="33%" align="center">

### ğŸ¤– Lab 03
**Governed Agentic AI**

ğŸš§ **COMING SOON**

Autonomous system governance

**Features:**
- Tool Authorization
- Action Approval Workflows
- Sandboxing & Limits
- Decision Audit Trails

[**ğŸ”® Preview Lab 03 â†’**](labs/governed-agentic-ai/)

**Time:** 4-5 hours  
**Difficulty:** ğŸ”´ Advanced

</td>
</tr>
</table>

### ğŸ—ºï¸ Learning Path

| Step | Action |
|------|--------|
| 1ï¸âƒ£ | ğŸ“š Start Here â†’ Lab 01 (Fundamentals) |
| 2ï¸âƒ£ | â†“ Lab 02 (RAG Security) |
| 3ï¸âƒ£ | â†“ Lab 03 (Agentic AI) |

> **ğŸ’¡ Recommended**: Complete labs in order. Each builds on concepts from the previous.

### Lab-Specific Learning

| Lab | You'll Master |
|-----|--------------|
| **Lab 01** | PII masking, injection detection, ABAC policies, performance monitoring |
| **Lab 02** | Context security, retrieval auth, citation tracking, embedding safety |
| **Lab 03** | Tool authorization, sandboxing, decision auditing, governance frameworks |

---
## ğŸš€ Quick Start

### Prerequisites

- âœ… **Python 3.11+**
- âœ… **LLM Provider** (choose one):
  - ğŸ¦™ [Ollama](https://ollama.com/download) - Recommended for local development
  - ğŸ¤– OpenAI API key - For cloud deployment  
  - âš¡ Any other LLM provider
- âœ… **[OPA](https://www.openpolicyagent.org/docs/latest/#running-opa)** - Open Policy Agent

### Installation
```bash
# 1. Clone repository
git clone https://github.com/SP-authonomy/ai-security-labs-handbook.git
cd ai-security-labs-handbook

# 2. Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment variables. E.g.
MODEL_PROVIDER=ollama
GEN_MODEL=llama3.2:1b
OLLAMA_HOST=http://localhost:11434
OPA_URL=http://localhost:8181/v1/data/ai/policy/allow
```
