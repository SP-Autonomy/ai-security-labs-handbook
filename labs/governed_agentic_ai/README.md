# Lab 03: Governed Agentic AI ğŸ¤–

<div align="center">

**Multi-Agent Systems with MCP-Style Tool Governance**

[![Lab Status](https://img.shields.io/badge/status-complete-success.svg)](.)
[![Difficulty](https://img.shields.io/badge/difficulty-advanced-red.svg)](.)
[![Time](https://img.shields.io/badge/time-3--4%20hours-blue.svg)](.)

[ğŸ¯ Overview](#overview) â€¢ [ğŸ¢ Architecture](#architecture) â€¢ [ğŸš€ Setup](#setup) â€¢ [ğŸ§ª Tests](#test-scenarios) â€¢ [ğŸ“Š Results](RESULTS.md)

</div>

---

## ğŸ¯ Overview

A multi-agent orchestration system demonstrating **Agent-to-Agent (A2A) governance** with MCP-style tool control, budgets, schema validation, sandboxing, and evidence logging.

### Key Features

| Security | Governance |
|----------|------------|
| âœ… Tool Allowlists per Agent | âœ… Budget Enforcement (calls + time) |
| âœ… JSON Schema Validation | âœ… Sandbox Path Traversal Protection |
| âœ… Side-Effect Detection | âœ… Append-Only Evidence Log |
| âœ… Exfiltration Pattern Detection | âœ… Agent Identity & Authorization |

### Learning Objectives

1. **Understand** agentic AI security challenges (unauthorized tool access, exfiltration)
2. **Implement** MCP-style tool registry with governance controls
3. **Enforce** per-agent tool allowlists and execution budgets
4. **Detect**